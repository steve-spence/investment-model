{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8CEs82W8R4_"
      },
      "source": [
        "# Run this in google colab\n",
        "# Things to set up\n",
        "1. Add FINNHUB_API_KEY to Secrets\n",
        "2. Add the accepted_stocks.json file to the same directory as this folder\n",
        "\n",
        "# Go to bottom to run code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdqyYCaEtIdR",
        "outputId": "0faf8b6b-f11b-4bbf-f76f-9faf593da8de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.11/dist-packages (6.0.11)\n",
            "Requirement already satisfied: finnhub-python in /usr/local/lib/python3.11/dist-packages (2.4.23)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from finnhub-python) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->finnhub-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->finnhub-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->finnhub-python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->finnhub-python) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install feedparser finnhub-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUvAqsJ9rlvH"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timezone, timedelta\n",
        "from abc import ABC, abstractmethod\n",
        "from google.colab import userdata, drive\n",
        "from typing import Optional\n",
        "from tqdm import tqdm\n",
        "import yfinance as yf\n",
        "import feedparser\n",
        "import requests\n",
        "import finnhub\n",
        "import time\n",
        "import json\n",
        "import sys\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVmHYY05r3zn"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Collecting Data from Yahoo and Zach Research (Finnhub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "zilMdmNjr41S"
      },
      "outputs": [],
      "source": [
        "class NewsSource:\n",
        "    \"\"\"\n",
        "    Abstract class for fetching news for a given stock symbol\n",
        "    \"\"\"\n",
        "    def __init__(self, accepted_stocks_location):\n",
        "        self.accepted_stocks = {}\n",
        "        self.accepted_stocks_path = accepted_stocks_location\n",
        "\n",
        "    def _load_stocks(self) -> None:\n",
        "        \"\"\"\n",
        "        Load the accepted_stocks.json file\n",
        "        \"\"\"\n",
        "        with open (self.accepted_stocks_path) as f: # This is relative to main.py I think\n",
        "            self.accepted_stocks = json.load(f)\n",
        "\n",
        "        # make key the symbol\n",
        "        self.accepted_stocks = {item.pop('symbol'): item for item in self.accepted_stocks}\n",
        "\n",
        "    def _load_news(self, symbol: str) -> list:\n",
        "        \"\"\"\n",
        "        Return a list of news for a given stock symbol\n",
        "        \"\"\"\n",
        "        # make sure we accept the symbol\n",
        "        if not self.accepted_stocks[symbol]:\n",
        "            raise Exception(\"Stock symbol not found in accepted_stocks.json\")\n",
        "\n",
        "    def get_accepted_stocks(self) -> dict:\n",
        "        \"\"\"\n",
        "        Return the accepted_stocks dictionary\n",
        "        \"\"\"\n",
        "        return self.accepted_stocks\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_news(self, *args, **kwargs) -> dict:\n",
        "        \"\"\"\n",
        "        Subclasses should implement their logic to fetch news (possibly using a shared approach).\n",
        "        Return format: {symbol: [news_items]}\n",
        "        \"\"\"\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "9mowt--kr-WU"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class FinnhubNews(NewsSource):\n",
        "    def __init__(self, accepted_stocks_location):\n",
        "        super().__init__(accepted_stocks_location)\n",
        "        api_key = userdata.get('FINNHUB_API_KEY')\n",
        "        if not api_key:\n",
        "            raise ValueError(\"No FINNHUB_API_KEY found in google colab sercrets.\")\n",
        "\n",
        "        # Instantiate Finnhub client\n",
        "        self.finnhub_client = finnhub.Client(api_key=api_key)\n",
        "\n",
        "\n",
        "    def _load_news(self, symbol: str, start_date: str, end_date: str):\n",
        "        \"\"\"\n",
        "        Return a list of news for a given stock symbol\n",
        "        \"\"\"\n",
        "        super()._load_news(symbol)\n",
        "        news_entries = self.finnhub_client.company_news(symbol, _from=start_date, to=end_date)\n",
        "        return [{'title': item['headline'], 'published' : item['datetime']} for item in news_entries]\n",
        "\n",
        "\n",
        "    def get_news(self, start_date: str, end_date: str, symbol: Optional[str] = None) -> dict:\n",
        "        \"\"\"\n",
        "        Get news for all data in accepted_stocks.json\n",
        "        If you pass in a symbol it will only update news for that specific symbol\n",
        "        \"\"\"\n",
        "        # initialize accepted_stocks\n",
        "        super()._load_stocks()\n",
        "\n",
        "        if symbol:\n",
        "            return {symbol: self._load_news(symbol, start_date, end_date)}\n",
        "\n",
        "        news_data = {}\n",
        "        for symbol in tqdm(self.accepted_stocks.keys(), desc=f'Getting finnhub company news from {start_date} to {end_date}'):\n",
        "            news_data[symbol] = self._load_news(symbol, start_date, end_date)\n",
        "            time.sleep(.75) # api limits\n",
        "        return news_data\n",
        "\n",
        "\n",
        "#print(FinnhubNews().get_news(symbol='AAPL',start_date='2024-06-01', end_date='2024-06-02'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "NCFKoKvIsAOj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class YahooNews(NewsSource):\n",
        "    def _load_news(self, symbol: str):\n",
        "        \"\"\"\n",
        "        Return a list of news for a given stock symbol\n",
        "        \"\"\"\n",
        "        super()._load_news(symbol)\n",
        "\n",
        "        # make sure we accept the symbol\n",
        "        if not self.accepted_stocks[symbol]:\n",
        "            return \"Stock symbol not found in accepted_stocks.json\"\n",
        "\n",
        "        # get the security name\n",
        "        security = self.accepted_stocks[symbol]['security'].lower().strip()\n",
        "        rss_url = f\"https://finance.yahoo.com/rss/2.0/headline?s={symbol}\"\n",
        "\n",
        "        feed = feedparser.parse(rss_url)\n",
        "\n",
        "        news_list = []\n",
        "        for i , entry in enumerate(feed.entries):\n",
        "            if security in entry.summary.lower(): # Todo: play around with not in vs in\n",
        "                continue\n",
        "            news_data = {\n",
        "                'title': entry.title,\n",
        "                'published': int(datetime.strptime(entry.published, '%a, %d %b %Y %H:%M:%S %z').timestamp())  # unix timestamp\n",
        "            }\n",
        "            news_list.append(news_data)\n",
        "\n",
        "        return news_list # [{title: 'title', published: 'published'}]\n",
        "\n",
        "    def get_news(self, symbol: Optional[str] = None) -> dict:\n",
        "        \"\"\"\n",
        "        Get news for all data in accepted_stocks.json\n",
        "        If you pass in a symbol it will only update news for that specific symbol\n",
        "        \"\"\"\n",
        "        super()._load_stocks()\n",
        "\n",
        "        if symbol:\n",
        "            return {symbol: self._load_news(symbol)}\n",
        "\n",
        "        news_data = {}\n",
        "        for symbol in tqdm(self.accepted_stocks.keys(), total=len(self.accepted_stocks.keys()), desc='Getting recent yahoo news'):\n",
        "            news_data[symbol] = self._load_news(symbol)\n",
        "        return news_data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "kxIBShMssCBW"
      },
      "outputs": [],
      "source": [
        "\n",
        "class StockNewsManager:\n",
        "    def __init__(self, directory='news'):\n",
        "        self.directory = directory\n",
        "        os.makedirs(self.directory, exist_ok=True)\n",
        "\n",
        "    def load_news(self, symbol: str):\n",
        "        file_path = os.path.join(self.directory, f\"{symbol}.json\")\n",
        "        with open(file_path, 'r') as file:\n",
        "            news_data = json.load(file)\n",
        "        return news_data\n",
        "\n",
        "    def save_news(self, symbol: str, news_list: list):\n",
        "        file_path = os.path.join(self.directory, f\"{symbol}.json\")\n",
        "\n",
        "        # Load existing news if the file exists\n",
        "        if os.path.exists(file_path):\n",
        "            with open(file_path, 'r') as file:\n",
        "                existing_news = json.load(file)\n",
        "        else:\n",
        "            existing_news = []\n",
        "\n",
        "        # Append new news items\n",
        "        existing_news.extend(news_list)\n",
        "\n",
        "        # Save updated news list back to json file\n",
        "        with open(file_path, 'w') as file:\n",
        "            json.dump(existing_news, file, indent=2)\n",
        "\n",
        "        print(f\"News saved successfully for {symbol}!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "JBPZI6YusDij"
      },
      "outputs": [],
      "source": [
        "def remove_bad_entries(news: dict):\n",
        "    \"\"\"\n",
        "    Remove news entries that do not have a 'published' key\n",
        "    \"\"\"\n",
        "    for symbol, news_list in news.items():\n",
        "        for news_source in news_list:\n",
        "            if 'posting_price' not in news_source:\n",
        "                news_list.remove(news_source)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "X8yqJql-sFtw"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_stock_data(news: list, accepted_stocks: dict):\n",
        "    \"\"\"\n",
        "    Save the price data for all news data for each stock symbol\n",
        "    \"\"\"\n",
        "\n",
        "    day_forecast = 7\n",
        "    rounding_precision = 8\n",
        "\n",
        "    # Get the price data for each symbol in the news directory\n",
        "    for symbol in tqdm(accepted_stocks.keys(), desc='Getting price data for stocks'):\n",
        "        if symbol not in news:\n",
        "            continue\n",
        "        recorded_dates = {} # list of dates we have already recorded stock data for\n",
        "        for news_source in news[symbol]: # {'title':, 'published':}\n",
        "            # Get the stock price at the time of the news\n",
        "\n",
        "            # Get the dates for the stock data\n",
        "            # We get current day and next because you cant input same day for both start and end\n",
        "            news_obj = datetime.fromtimestamp(news_source['published'], tz=timezone.utc)\n",
        "            start_date = str(news_obj).split(' ')[0]\n",
        "            end_date = str(news_obj + timedelta(days=day_forecast)).split(' ')[0] # offset by day_forecast the amount of days to store\n",
        "\n",
        "            # Check if we have data for that date\n",
        "            if start_date not in recorded_dates:\n",
        "                #print(f\"Getting stock data for {symbol} from {start_date} to {end_date}\")\n",
        "                try: # Check if we have data for that date\n",
        "                    yf_data = yf.download(tickers=symbol, start=start_date, end=end_date, progress=False)\n",
        "                    for i in range(day_forecast):\n",
        "                        # the next dates of the news\n",
        "                        current_date = str(news_obj + timedelta(days=i)).split(' ')[0]\n",
        "\n",
        "                        # Save the stock data for that date\n",
        "                        recorded_dates[current_date] = {\n",
        "                            'open': round(yf_data.iloc[i]['Open'].values[0], rounding_precision),\n",
        "                            'close': round(yf_data.iloc[i]['Close'].values[-1], rounding_precision)\n",
        "                            }\n",
        "\n",
        "                        # if the next day is in the recorded_dates, break\n",
        "                        if str(news_obj + timedelta(days=1)).split(' ')[0] in recorded_dates:\n",
        "                            break\n",
        "\n",
        "                except Exception as e: # index exception and api limit exception\n",
        "                    #print(f\"No stock data found for {symbol} on {start_date}, Error: \", e)\n",
        "                    news[symbol].remove(news_source)\n",
        "                    continue\n",
        "\n",
        "            # Calculate the variables for that day\n",
        "            posting_price = recorded_dates[start_date]['open']\n",
        "            close_price = recorded_dates[start_date]['close']\n",
        "            percent_change = round(((close_price - posting_price) / posting_price) * 100, rounding_precision)\n",
        "\n",
        "            # Add the stock data to the news source\n",
        "            news_source['posting_price'] = posting_price\n",
        "            news_source['close_price'] = close_price\n",
        "            news_source['percent_change'] = percent_change\n",
        "            time.sleep(.1) # api limits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "3ZBVxlonsE61"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_news(start_date: str, end_date: str, current_file_path: str):\n",
        "    # initialize news sources\n",
        "    yahoo = YahooNews(current_file_path+'accepted_stocks2.json')\n",
        "    finnhub = FinnhubNews(current_file_path+'accepted_stocks2.json')\n",
        "\n",
        "    # initialize file manager for news data\n",
        "    manager = StockNewsManager(current_file_path+'news')\n",
        "\n",
        "    # Get title and published from sources\n",
        "    finnhub_news = finnhub.get_news(start_date=start_date, end_date=end_date)\n",
        "    yahoo_news = yahoo.get_news() # {symbol: [news_items]}\n",
        "\n",
        "    # Add more news sources here\n",
        "    all_news = [yahoo_news, finnhub_news]\n",
        "\n",
        "    # save the stock prices\n",
        "    for news in all_news:\n",
        "        load_stock_data(news=news, accepted_stocks=yahoo.get_accepted_stocks())\n",
        "        remove_bad_entries(news=news)\n",
        "\n",
        "    # Save the news data to the file\n",
        "    for news_data in all_news:\n",
        "        for symbol, news_list in tqdm(news_data.items(), desc='Witing price data to file'):\n",
        "            manager.save_news(symbol, news_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j4Ci2WPsIQq",
        "outputId": "bae08c52-d3a5-4e00-ce84-a7fdc94cce7d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Getting finnhub company news from 2024-04-01 to 2024-04-30: 100%|██████████| 9/9 [00:09<00:00,  1.06s/it]\n",
            "Getting recent yahoo news: 100%|██████████| 9/9 [00:01<00:00,  6.90it/s]\n",
            "Getting price data for stocks: 100%|██████████| 9/9 [00:10<00:00,  1.15s/it]\n",
            "Getting price data for stocks: 100%|██████████| 9/9 [02:13<00:00, 14.79s/it]\n",
            "Witing price data to file: 100%|██████████| 9/9 [00:00<00:00, 86.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "News saved successfully for MMM!\n",
            "News saved successfully for AOS!\n",
            "News saved successfully for ABT!\n",
            "News saved successfully for ABBV!\n",
            "News saved successfully for ACN!\n",
            "News saved successfully for ADBE!\n",
            "News saved successfully for AMD!\n",
            "News saved successfully for AES!\n",
            "News saved successfully for AFL!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rWiting price data to file:   0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "News saved successfully for MMM!\n",
            "News saved successfully for AOS!\n",
            "News saved successfully for ABT!\n",
            "News saved successfully for ABBV!\n",
            "News saved successfully for ACN!\n",
            "News saved successfully for ADBE!\n",
            "News saved successfully for AMD!\n",
            "News saved successfully for AES!\n",
            "News saved successfully for AFL!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Witing price data to file: 100%|██████████| 9/9 [00:00<00:00, 87.23it/s]\n"
          ]
        }
      ],
      "source": [
        "file_location='/content/drive/MyDrive/Colab Notebooks/' # news will be generated into a 'news' folder here, this is also where accepted_stocks.json is located\n",
        "start_date = '2024-04-01'\n",
        "end_date = '2024-04-30'\n",
        "load_news(start_date=start_date, end_date=end_date, current_file_path=file_location)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
